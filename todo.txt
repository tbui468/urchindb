Look here for hints on creating a database:
    https://cs.brown.edu/courses/csci1270/website_2021/

Relational Database
    Is it called relational because relational operators (along with equality operators) can be used to query 
    specific data (whereas a key/value database can only query based on equality)?  Seems to make sense

Schemas <----------start here with creating db_create()
    db_open() can only be called on databases that already exist
    User must call db_create(const char* name, char** field_names, enum DbTypes* field_types) to create a schema first <---------implement this function
    db_insert() //create new record
    db_update() //update existing record
    db_delete() //delete exiting record
    db_select(char* field_name, bool (*cmp)(void)); //selects all records where field satifies cmp function (eg, returns true)
        will replace with SQL engine later.  This function is just a temporary solution to test fetching data
        what kind of bytecode will the vm use?

Trees
    Let's say we use a binary tree to store records index by primary key
        Would need to rebalance tree as more records are added to make sure it's balanced
        otherwise a binary tree is pointless.  Also useful to rebalance trees if too high
        for the number of nodes

        How should the binary tree be stored?
            after update_count and free list root, store the root node
            Reading an index file will convert data to a binary tree
            Writing a binary tree to file will do just that

            Index by primary key
                primary key
                offset_count = 1
                record offset in data file (primary keys are unique, so just one offset)

            Index by age
                age
                offset_count = ???
                record offset in data file (may not be unique, so could be more than one offset)

        Need a function to rebalance tree after a few adds
            traverse tree and find lowest and highest values
            pick median value as the root
            rebalance tree based off that new root

Paging - NOTE: reset BUCKETS_MAX back to 1024 before running tests for cache buffers
    Test results without paging with 1024 buckets (bucket count didn't seem to make a noticeable difference)
        seems like file access was the bottleneck, and not traversing the hash chains.
        n = 500:  10.15s
        n = 1000: 39.54s
        n = 2000: 156.34

    Cache buffer - single process without any multiprocessor protection
        n = 500:  0.29s
        n = 1000: 0.91s
        n = 2000: 2.66s

    Cache buffer - multiprocess protection / file locking / copy-on-write / update stale data on read

        Single block
            n = 500:   0.31s
            n = 1000:  1.01s
            n = 2000:  2.87s
            n = 4000:  9.40s
            n = 8000:  36.08s
            n = 16000: 142.51s

        4096 byte blocks
            don't need this yet since single block speed is pretty fast - may change if files become significantly larger

Implement key/value database

    Index Record:
        uint32_t next_off
        uint32_t data_off
        uint32_t data_size
        uint32_t key_size
        char* key

    Data Record
        char* data

    enum DbType {
        DB_INT,
        DB_STRING
    };

    struct Field {
        char* name;
        enum DbType type;
    };

    struct Field fields[3];
    fields[0].name = "first_name";
    fields[0].type = DB_STRING;
    fields[0].name = "last_name";
    fields[0].type = DB_STRING;
    fields[0].name = "age";
    fields[0].type = DB_INT;
    db_create("Students", fields, 3);

    Questions:
        How are data files and index files stored now?
            data should be stored with fields sequentially: primary key, and then fields in order
                DB_STRING start with an uint32_t specifying length of string, followed by string
                DB_INT is just a 4 byte integer for now
            index file initially create with primary key as index, stored in tree (just use binary tree for simplicity now)
                each node has the primary key, and also the offset into the data file
                indexing by a different field will create a new index file
                    students.idx.primary_key - this needs to be disallowed as a field name
                    students.idx.age
                    students.dat

    When opening a database, must define a schema for data
        db_open() <-----only works with database that already exists
        db_create() <-----need to be called before db_open can be used, fails if database with given name already exists
        db_create("students", char** fields, enum db_types* types);  <---returns 0 if database was succesfully create
            user still needs to call db_open to open the newly created database
            how about indexing tables?  Default is primary key (uint32_t)
            db_index(db, char* field) <---create new index using this field in table

        B tree instead of hash table Why use a b tree?  If data is index using a b-tree, we can search for ALL records that match a condition
                eg, if age > 0 and age < 10.
                Right now, we can't do that
            But would require user defining a table
                database would assign primary keys and index by primary keys by default
                when making table, user could specify which field to index

    db_insert
    db_update
    db_delete
    db_select(db, "age", age_fun); //select all records where age field is passed to age_fun, and result is true

    SQL and engine to search database

    Make it a distributed database - need to add network support
        how to keep all databases consistent?  !!!consensus!!!
        Should all instances have the same internal format, or just the same keys/values?
        Would also need to timestamp stuff
